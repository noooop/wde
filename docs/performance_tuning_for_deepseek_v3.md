
# 对 DeepSeek-V3 / R1 做推理优化

## 引言

deepseek-r1 模型架构
- embed_tokens -> 3 * Dense MLP Layers -> 58 * MOE Layers -> lm_head 组成
- 每个 Layers 由 input_layernorm -> self_attn -> post_attention_layernorm -> mlp 组成
- self_attn 有 MHA 和 MLA 两种实现方式

按总参数量 657B 算：
- deepseek-v3/r1 单个 Expert 7168 X 2048 X 3 = 44M
- 58层 moe 总共 58 * (256+1) * 44M ≈ 640 B
- 剩下的参数 657 B - 640 B ≈ 17B

按激活 37B 算：
- 58 * (8 + 1) * 44M ≈ 22B
- 37B - 22B ≈ 15B

将不包括moe的激活参数称主干网络。

本系统尝试部署主干网络和kvcache部署在一个集群，moe部署在另一个集群，主干网络通过rpc调用moe集群。

> 如果使用现在主流的单机内做8卡 TP，机器间做 PP 部署，使用 H20 96Gx8 或者H800 80G x16， 没有多少空间给 kvcache
> 而且因为moe的稀疏性，没法在正常的 batchsize（延迟）下将 moe 打到 compute bound

而且 rpc调用moe 的方式每个节点都可以单独扩容缩容，负载平衡，故障转移

更重要的是随着规模增加 主干网络集群 和 moe集群 可以分开单独优化

大模型推理大部分情况下都是 memory bound，换用更快显存的 GPU 效果立竿见影。

对于主干网络：

如果GPU支持NVLink，
- 可以使用8卡TP，降低延迟，增加kvcache大小，支持更长上下文
- 可以使用sp，提高超长上下文性能
- 你也可以认为，对于一个 15B ~ 17B 的模型，没必要继续优化

> Multi-head Latent Attention (MLA) 实际上就只有一个 head，不少工作正在优化 MLA tp 性能

对于 moe：

如果GPU支持NVLink，可以使用8卡 EP，如果机器间有 InfiniBand， 可以大规模EP，最高可以 256-way EP

但是随着并行度增加，单节点故障会扩散到更多节点

> 除了compute bound和 memory bound，还要考虑夸卡和夸机的通信带宽，大规模的ep有可能网卡带宽成为瓶颈。

最后rpc会引入比较大的通信开销，所以使用异步调度（双 batch 重叠）来掩盖通信开销，提高整体吞吐。


# 下面尝试搭 4090 集群

## 基础 IO 性能

```commandline
python -m benchmarks.deepseek_v3.baseline.io
```

> 硬件
> cpu: 12700kf
> gpu: 4090
> memory：DDR4 3600 32 * 4
> ssd: 2T PCIe4.0

> - kvikio: ssd to gpu 3.0453657519158623 GB/s
> - kvikio: gpu to ssd 5.641049281000345 GB/s
> 
> - numpy: cpu to ssd 3.4756728820261786 GB/s
> - numpy: ssd to cpu 6.5520971491038305 GB/s
> - numpy: cpu to cpu 19.668772559522562 GB/s
> 
> - torch: cpu to ssd 2.120535333725255 GB/s
> - torch: ssd to cpu 3.6678152118238767 GB/s
> - torch: cpu to cpu 18.31373723387411 GB/s
> 
> - torch: gpu to ssd 1.3003456617848537 GB/s
> - torch: ssd to gpu 2.7394149293058145 GB/s
> - torch: gpu to gpu 13833.578593932974 GB/s
> - torch: gpu to cpu 19.467226540853233 GB/s
> - torch: cpu to gpu 19.653485611881948 GB/s

- ssd 与 gpu 传输，走 GPUDirect Storage，写3GB/s, 5GB/s
- ssd 与 内存 传输, 写3GB/s, 6GB/s
- 内存拷贝 19 GB/s
- 内存 与 gpu 传输 19 GB/s
- 显存拷贝 > 1T/s

## 每层基础性能测试 和 tuning block_wise kernel

下面对每个模块进行测试和调优

### embed_tokens

```commandline
python -m benchmarks.deepseek_v3.baseline.embed_tokens
```

| tokens | test_cpu (ms) | test_cpu_h2d (ms) | test_gpu (ms) | 
|--------|---------------|-------------------|---------------|
| 1      | 0.0034        | 0.0119            | 0.0094        |
| 2      | 0.004         | 0.0131            | 0.01          |
| 4      | 0.0052        | 0.0151            | 0.0113        |
| 8      | 0.0072        | 0.0253            | 0.0158        |
| 16     | 0.0113        | 0.0403            | 0.0189        |
| 32     | 0.0166        | 0.0776            | 0.0229        |
| 64     | 0.0293        | 0.1483            | 0.0332        |
| 128    | 0.0549        | 0.2221            | 0.0582        |
| 256    | 0.1086        | 0.3649            | 0.1166        |
| 512    | 0.506         | 0.7224            | 0.276         |
| 1024   | 1.1085        | 1.7059            | 0.7723        |
| 2048   | 2.2642        | 4.0767            | 2.2582        |


embed_tokens 占用 129280 * 7168 * bfloat16 = 1.7266 G 空间

将 embed_tokens 放在 内存节省 1.7 G显存，增加一倍的延迟，比如 1024 个 tokens，1.7059 ms vs 0.7723 ms

### Dense MLP

```commandline
python -m benchmarks.deepseek_v3.baseline.mlp
```

| batchsize | Throughput default (qps) | Latency default (ms) | Throughput tuning  (qps) | Latency tuning (ms) |
|-----------|--------------------------|----------------------|--------------------------|---------------------|
| 1         | 1227.5465                | 0.8146               | 2027.1755                | 0.4933              |
| 2         | 2353.5548                | 0.8498               | 4048.442                 | 0.494               |
| 4         | 5102.1339                | 0.784                | 8129.8989                | 0.492               |
| 8         | 10153.9398               | 0.7879               | 15808.5559               | 0.5061              |
| 16        | 20243.2187               | 0.7904               | 32168.2949               | 0.4974              |
| 32        | 40391.0434               | 0.7923               | 62756.3363               | 0.5099              |
| 64        | 80344.6857               | 0.7966               | 117082.4931              | 0.5466              |
| 128       | 146680.4137              | 0.8726               | 191989.8044              | 0.6667              |
| 256       | 191909.4327              | 1.334                | 203401.6139              | 1.2586              |
| 512       | 200350.8096              | 2.5555               | 203489.6868              | 2.5161              |
| 1024      | 215357.1594              | 4.7549               | 216187.8324              | 4.7366              |
| 2048      | 216516.6678              | 9.4589               | 233357.7741              | 8.7762              |
| 4096      | 216938.4271              | 18.8809              | 232153.6517              | 17.6435             |
| 8192      | 214935.3783              | 38.1138              | 228174.4757              | 35.9024             |

<img src="https://github.com/noooop/noooop.github.io/blob/main/benchmarking/wde/0.4.0/deepseek_v3/mlp.png?raw=true" width="400">

经过调优，所有 batchsize 都有不同程度提高

### attention

```commandline
python -m benchmarks.deepseek_v3.baseline.mha
python -m benchmarks.deepseek_v3.baseline.mla
```

#### prefile 性能

| batchsize | Throughput (qps) | Latency mla (ms) | Throughput (qps) | Latency mha (ms) |
|-----------|------------------|------------------|------------------|------------------|
| 1         | 1751.8295        | 0.5708           | 1703.8096        | 0.5869           |
| 2         | 3451.4117        | 0.5795           | 3352.1259        | 0.5966           |
| 4         | 6877.5817        | 0.5816           | 6738.3539        | 0.5936           |
| 8         | 13693.8928       | 0.5842           | 13147.8624       | 0.6085           |
| 16        | 26816.792        | 0.5966           | 26744.0153       | 0.5983           |
| 32        | 53119.7159       | 0.6024           | 52289.5024       | 0.612            |
| 64        | 101584.3927      | 0.63             | 100250.9516      | 0.6384           |
| 128       | 194949.1478      | 0.6566           | 189581.9336      | 0.6752           |
| 256       | 281159.5172      | 0.9105           | 277699.4789      | 0.9219           |
| 512       | 303330.1899      | 1.6879           | 283710.7794      | 1.8047           |
| 1024      | 318689.1558      | 3.2132           | 297717.3539      | 3.4395           |
| 2048      | 299143.7379      | 6.8462           | 280406.7255      | 7.3037           |
| 4096      | 255266.4138      | 16.046           | 242401.6491      | 16.8976          |
| 8192      | 195495.9716      | 41.9037          | 188563.6865      | 43.4442          |

<img src="https://github.com/noooop/noooop.github.io/blob/main/benchmarking/wde/0.4.0/deepseek_v3/prefill.png?raw=true" width="400">

> 所有 batchsize, mla 都比 mha 实现略好一点点，理论上应该是一样的
> prefile 是计算密集型操作，mla 和 mha 计算量是一样的


#### decoding 性能

| batchsize | Throughput (qps) | Latency mla (ms) | Throughput (qps) | Latency mha (ms) |
|-----------|------------------|------------------|------------------|------------------|
| 1         | 1062.435         | 0.9412           | 1686.092         | 0.5931           |
| 2         | 2119.0975        | 0.9438           | 3403.8274        | 0.5876           |
| 4         | 4238.2481        | 0.9438           | 6873.3376        | 0.582            |
| 8         | 8506.1351        | 0.9405           | 13592.8092       | 0.5885           |
| 16        | 16967.363        | 0.943            | 26859.8711       | 0.5957           |
| 32        | 33907.8187       | 0.9437           | 54041.7723       | 0.5921           |
| 64        | 67673.8617       | 0.9457           | 107309.3837      | 0.5964           |
| 128       | 134766.9944      | 0.9498           | 214599.0133      | 0.5965           |
| 256       | 269700.6359      | 0.9492           | 431633.5531      | 0.5931           |
| 512       | 544969.9866      | 0.9395           | 843926.59        | 0.6067           |
| 1024      | 1100639.025      | 0.9304           | 1546179.59       | 0.6623           |
| 2048      | 2168674.666      | 0.9444           | 2618009.996      | 0.7823           |
| 4096      | 4089861.037      | 1.0015           | 4044085.588      | 1.0128           |
| 8192      | 7506802.765      | 1.0913           | 5481167.119      | 1.4946           |
| 16384     | 12679673.56      | 1.2921           | 6706518.274      | 2.443            |

<img src="https://github.com/noooop/noooop.github.io/blob/main/benchmarking/wde/0.4.0/deepseek_v3/decoding.png?raw=true" width="400">

> 理论上 decoding 显存带宽瓶颈， mla 需要读的数据量少，应该有优势
> 但实际上优势只有到 kv 长度 4096 以上才能体现
> 可能是 mla 使用 triton kernel，而 mha 使用的 flash attention 使用 cuda实现的
> 蹲 [flashinfer 的 mla 实现](https://github.com/flashinfer-ai/flashinfer/issues/897)


#### kv cache

10G 显存能放多长的 kvcache

- MHA 10G (10 * 1024 * 1024 * 1024) / num_attention_heads(128) / qk_head_dim(128+64) / num_hidden_layers(61) / kv(2) / bf16(2) = 1790
- MLA 10G (10 * 1024 * 1024 * 1024) / c_cache_dim(512+64) / num_hidden_layers(61) / bf16(2) = 152797

使用 MLA，相比 MHA kv cache 多 152797 / 1790 = 85 倍


### dense_layer

deepseek 前三层mlp为 dense layer

```commandline
python -m benchmarks.deepseek_v3.baseline.dense_layer
python -m benchmarks.deepseek_v3.baseline.dense_layer_mla
```

| batchsize | Throughput (qps) | Latency mla (ms) | Throughput (qps) | Latency mha (ms) |
|-----------|------------------|------------------|------------------|------------------|
| 1         | 965.6634         | 1.0356           | 960.1625         | 1.0415           |
| 2         | 1913.3537        | 1.0453           | 1883.9215        | 1.0616           |
| 4         | 3795.3825        | 1.0539           | 3782.8764        | 1.0574           |
| 8         | 7587.7302        | 1.0543           | 7522.2197        | 1.0635           |
| 16        | 15225.8292       | 1.0508           | 14976.1849       | 1.0684           |
| 32        | 29587.1335       | 1.0816           | 29386.658        | 1.0889           |
| 64        | 55868.2548       | 1.1456           | 54989.1454       | 1.1639           |
| 128       | 98510.4163       | 1.2994           | 97345.9435       | 1.3149           |
| 256       | 119289.7033      | 2.146            | 118419.1396      | 2.1618           |
| 512       | 123999.0456      | 4.1291           | 120171.7412      | 4.2606           |
| 1024      | 131428.5501      | 7.7913           | 127180.2775      | 8.0516           |
| 2048      | 131118.9496      | 15.6194          | 126989.3667      | 16.1273          |
| 4096      | 120853.549       | 33.8923          | 118023.0774      | 34.7051          |
| 8192      | 105137.8752      | 77.9167          | 103678.9907      | 79.0131          |

<img src="https://github.com/noooop/noooop.github.io/blob/main/benchmarking/wde/0.4.0/deepseek_v3/dense_layer.png?raw=true" width="400">

batchsize 256 吞吐左右饱和， 此时延迟为 mla 2.146 ms， mha 2.1618 ms

### remote moe

```commandline
python -m benchmarks.deepseek_v3.baseline.fused_moe
```

#### Throughput-Latency

| batchsize | Throughput tuning  (qps) | Latency tuning (ms) | Throughput default (qps) | Latency default (ms) |
|-----------|--------------------------|---------------------|--------------------------|----------------------|
| 1         | 1331.6056                | 0.751               | 1263.8813                | 0.7912               |
| 2         | 2587.4249                | 0.773               | 2497.5737                | 0.8008               |
| 4         | 5065.7448                | 0.7896              | 4941.7237                | 0.8094               |
| 8         | 10164.6871               | 0.787               | 9679.6301                | 0.8265               |
| 16        | 19996.213                | 0.8002              | 18672.5177               | 0.8569               |
| 32        | 38170.7831               | 0.8383              | 37010.1289               | 0.8646               |
| 64        | 54263.0465               | 1.1794              | 72908.3447               | 0.8778               |
| 128       | 93994.9905               | 1.3618              | 108151.9444              | 1.1835               |
| 256       | 116924.1495              | 2.1895              | 131143.9157              | 1.9521               |
| 512       | 123706.5887              | 4.1388              | 142952.0141              | 3.5816               |
| 1024      | 164923.2731              | 6.2089              | 151701.552               | 6.7501               |
| 2048      | 170112.5987              | 12.0391             | 156523.2044              | 13.0843              |
| 4096      | 200066.1086              | 20.4732             | 158377.2615              | 25.8623              |

<img src="https://github.com/noooop/noooop.github.io/blob/main/benchmarking/wde/0.4.0/deepseek_v3/fused_moe.png?raw=true" width="400">

这个调优在 128-1024 段还不如不调优，需要进一步优化

#### 网络带宽

取 batchsize = 128， 延迟 1.1835 ms

rpc 需要的网络带宽 =  hidden_size(7168) * batchsize(128) * bf16(2) * io(2)  / 1 ms = 3.4 GB/s

10G网比较稳妥，不需要50G网

#### 所有moe层

考虑所有moe层，58 层 * (1ms 计算 + 1 ms io) = 116 ms

进一步优化延迟需要考虑ep，同时增加网络带宽


### backbone

```commandline
python -m benchmarks.deepseek_v3.baseline.fused_moe
```

| batchsize | Throughput (qps) | Latency mla (ms) | Throughput (qps) | Latency mha (ms) |
|-----------|------------------|------------------|------------------|------------------|
| 1         | 35.3614          | 28.2795          | 34.6577          | 28.8536          |
| 2         | 69.4293          | 28.8063          | 67.3707          | 29.6865          |
| 4         | 135.4152         | 29.5388          | 136.9993         | 29.1972          |
| 8         | 269.9692         | 29.633           | 275.7618         | 29.0105          |
| 16        | 541.6291         | 29.5405          | 537.8061         | 29.7505          |
| 32        | 1088.6981        | 29.3929          | 1090.9523        | 29.3322          |
| 64        | 2215.8376        | 28.883           | 2215.4095        | 28.8886          |
| 128       | 3896.4984        | 32.85            | 3892.8995        | 32.8804          |
| 256       | 4645.3754        | 55.1086          | 4645.3446        | 55.1089          |
| 512       | 4605.7977        | 111.1642         | 4602.9761        | 111.2324         |
| 1024      | 4690.9429        | 218.293          | 4697.3618        | 217.9947         |
| 2048      | 4304.3428        | 475.7985         | 4307.0439        | 475.5001         |
| 4096      | 3666.0362        | 1117.283         | 3664.2           | 1117.8429        |
| 8192      | 2899.2486        | 2825.5597        | 2894.3747        | 2830.3177        |

batchsize = 128 不错的 Throughput-Latency 平衡点，此时吞吐为 3896 token/s
batchsize = 256 吞吐饱和

随着序列长度增加，延迟也会响应时间相应增加

|       | mla      | mha     | 
|-------|----------|---------|
| 1     | 29.1229  | 28.7521 | 
| 2     | 28.7804  | 28.7021 | 
| 4     | 28.0831  | 28.5561 | 
| 8     | 28.3906  | 28.5935 | 
| 16    | 28.9337  | 28.9736 | 
| 32    | 28.596   | 28.7021 | 
| 64    | 28.7738  | 29.1493 | 
| 128   | 28.6681  | 29.3534 | 
| 256   | 28.5722  | 29.4061 | 
| 512   | 28.4492  | 29.0401 | 
| 1024  | 30.0839  | 30.0759 | 
| 2048  | 37.4145  | 37.434  | 
| 4096  | 51.8346  | 51.8454 | 
| 8192  | 80.5349  | 80.557  | 
| 16384 | 138.9774 | 138.976 | 

deepseek v3 支持 128K 上下文能力，但要真的落地需要sp

## 小结

结果理论估计和实际测试

使用 29台 4090 部署 fused_moe， 一台部署 backbone， 留不到 10G 作为 kv cache

batchsize = 128，吞吐 3896 token/s， 延迟 116 ms + 32 ms




# 一些不靠谱的部署方式

一些脑洞打开的部署方式，写下来图一乐

## 从 ssd 加载 MOE Layer

第一次看 deepseek v3 论文时，觉得这个架构好啊，256个专家只激活8个，使用1T ssd，使用的时候从ssd异步加载，一张 4090 + 1T ssd 就可以推理 657B 的模型

- 加载一个专家的延迟： 44M / 5GB/s = 8.6 ms
- 加载所有层的专家：58 * 8 * 8.6 ms = 4s

一个 token 4s， amazing

如果 batchsize > 1, 极限的需要把所有专家都加载进来

- 58层 moe 总共 58 * (256+1) * 44M ≈ 640 B
- 640 B / 5GB/s ≈ 128s 

128s，需要超大的batchsize去做 Computation-Communication Overlap

使用量化模型 和 pcie5.0 ssd可能会快一些，但使用ssd依然是图一乐

| Quants  | Disk Size | Details                                    |
|---------|-----------|--------------------------------------------| 
| Q2_K_XS | 207GB     | Q2 everything, Q4 embed, Q6 lm_head        |
| Q2_K_L  | 228GB     | Q3 down_proj Q2 rest, Q4 embed, Q6 lm_head |
| Q3_K_M  | 298GB     | Standard Q3_K_M                            |
| Q4_K_M  | 377GB     | Standard Q4_K_M                            |
| Q5_K_M  | 443GB     | Standard Q5_K_M                            |
| Q6_K    | 513GB     | Standard Q6_K                              |
| Q8_0    | 712GB     | Standard Q8_0                              |

除非使用使用[闪迪高带宽闪存HBF](https://www.tomshardware.com/pc-components/dram/sandisks-new-hbf-memory-enables-up-to-4tb-of-vram-on-gpus-matches-hbm-bandwidth-at-higher-capacity)

## 内存 offloading MOE Layer

ssd 加载 MOE Layer 不行，那就使用内存， 657B 的模型需要 8 台 128G内存的机器，或者一台1T的机器。

- 加载一个专家的延迟： 44M / 20GB/s = 2ms
- 加载所有层的专家：58 * 8 * 2ms = 928 ms

一秒一个token， amazing

测试一个 expert

```commandline
python -m benchmarks.deepseek_v3.baseline.expert
```

| batchsize | Throughput: | Latency: |
|-----------|-------------|----------|
| 1         | 9800.3368   | 0.102    |
| 2         | 19370.1261  | 0.1033   |
| 4         | 38763.525   | 0.1032   |
| 8         | 78143.7576  | 0.1024   |
| 16        | 155176.7347 | 0.1031   |
| 32        | 305446.1915 | 0.1048   |
| 64        | 564974.0456 | 0.1133   |
| 128       | 941223.2549 | 0.136    |
| 256       | 1349401.401 | 0.1897   |
| 512       | 1604349.592 | 0.3191   |
| 1024      | 1768248.637 | 0.5791   |
| 2048      | 1859222.943 | 1.1015   |
| 4096      | 1872228.641 | 2.1878   |
| 8192      | 1907057.295 | 4.2956   |

- 单个expert需要 batchsize = 4096 才能实现 Computation-Communication Overlap
- 总体 batchsize 要达到 4096 * 32 = 131072
- 一个step延迟至少 58 * 256 * 2ms = 30s 
- 131072 / 30s = 4369 tokens/s amazing

如果是8台机器，可以做8路ep，延迟降8倍，单token延迟100~200ms，想想有点小激动

ep需要的带宽和tp差不多，batchsize小的时候还可以，加大 batchsize 没有 NVLink 和 InfiniBand 基本上图一乐


## Expert 级别 rpc

- Layer 级别 rpc 相当于 Layer 级别 pp，网络io 等于 N token * hidden_states 
- Expert 级别 rpc 相当于 ep，Broadcast+Reduce，naive的实现就是 io 放大 256 倍..，当然可以用ring-reduce等方法优化

## offloading

如果显存不够，应该把kvcache交换到内存，还是应该把模型参数交换到内存

- kvcache 需要将前一层交换出gpu，再把后一层交换回gpu
- 模型参数是只读的，只需要交换会cpu

所以如果要交换的数据量一样，优先交换模型参数

15B 的 backbone offloading 需要 15B / 20 GB/s = 750 ms 

换成4通道DDR5内存和pcie5.0延迟都太大

所以所有参数放在显存里面才快


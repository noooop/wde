{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d7434f",
   "metadata": {},
   "source": [
    "# 0. wde.agents 支持多种客户端"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8d344",
   "metadata": {},
   "source": [
    "首先将 wde 目录加入 python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c63867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "pwd = Path(os.getcwd())\n",
    "sys.path.append(str(pwd.parent.parent.parent))\n",
    "os.chdir(str(pwd.parent.parent.parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df78507",
   "metadata": {},
   "source": [
    "导入 LLMAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6d66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wde.agents import LLMAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c4730",
   "metadata": {},
   "source": [
    "演示使用 Qwen/Qwen2-7B-Instruct 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72c5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Qwen/Qwen2-7B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b87cfe8",
   "metadata": {},
   "source": [
    "演示的提示词为 \"给我介绍一下大型语言模型。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb660451",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"给我介绍一下大型语言模型。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4b9500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "{'type': 'zeroclient', 'model': 'Qwen/Qwen2-7B-Instruct'}\n",
      "stream=False\n",
      "大型语言模型是人工智能领域中的一种神经网络模型，主要用于生成和理解人类语言。它们通过学习大量的文本数据（如书籍、文章、新闻、社交媒体文本等）来捕捉语言的复杂结构和语义，从而能够生成新的、连贯的文本，回答问题，甚至进行对话。\n",
      "\n",
      "关键特征和组成部分通常包括：\n",
      "\n",
      "1. **Transformer架构**：这是大型语言模型中广泛使用的一种架构，相比以前的RNN（递归神经网络）架构，Transformer能够并行处理输入文本中的所有元素，显著提高了训练和应用的效率。\n",
      "\n",
      "2. **自回归生成**：许多大型语言模型采用了自回归机制，这意味着模型在预测词时依赖于之前所有已经生成的词的输出，使得生成的文本具备逻辑性和连贯性。\n",
      "\n",
      "3. **预训练-微调**：大型模型通常首先通过在大量无标注文本上进行预训练，学习到通用的语言表征和模式。然后，根据特定任务（如文本生成、问答、翻译等）进行微调，以优化这些通用表示在特定任务上的性能。\n",
      "\n",
      "4. **大规模参数量**：这类模型往往包含数亿到数百亿个参数，需要大量的计算资源进行训练。这不仅是对硬件资源的要求，也是训练时间上的巨大挑战。\n",
      "\n",
      "5. **多语种支持**：随着全球化和多语言交流的需求，大型语言模型也能支持多种语言的处理，提高了其适用性和广泛性。\n",
      "\n",
      "大型语言模型在多个领域有广泛应用，例如：\n",
      "\n",
      "- **文本生成**：包括文章写作、故事创作、代码生成、自动化文档等。\n",
      "- **机器翻译**：实现不同语言之间的自动翻译。\n",
      "- **问答系统**：能够理解问题并从大量文本中提取信息以提供准确的回答。\n",
      "- **对话系统**：在聊天机器人、智能助手中应用，提供自然流畅的对话体验。\n",
      "\n",
      "大型语言模型是人工智能研究的重要成果，正逐渐改变着信息处理、内容生成和人机交互的方式。\n",
      "stream=True\n",
      "大型语言模型是人工智能研究领域内的一种基于深度学习的神经网络模型，被设计为能够生成类似于人类语言的文本。这些模型通过学习和理解大量文本数据中的语义、语法和关联关系来工作，展现出自动生成语言文本的能力，包括但不限于文章、对话、故事、代码和摘要等。\n",
      "\n",
      "### 主要特点：\n",
      "\n",
      "1. **大规模训练数据**：大型语言模型通常基于互联网上大量文本数据进行训练，这使得它们能够学习到广泛的语言表达和上下文知识。\n",
      "\n",
      "2. **深度学习架构**：这些模型经常使用递归神经网络（如LSTM或Transformer）、多层前向神经网络或其他复杂架构，通过多层神经元之间的连接和非线性变换来学习文本特征。\n",
      "\n",
      "3. **生成多样文本**：通过给定的引导文本或指令，大型语言模型可以生成各种类型的自然语言文本，展现了其多样性和适应性。\n",
      "\n",
      "4. **上下文敏感**：它们能够根据上下文生成适当的响应，理解复杂句子结构和逻辑关系。\n",
      "\n",
      "5. **语言理解与生成**：不仅能够生成文本，还能够进行语言理解，执行文本推理等操作。\n",
      "\n",
      "### 应用领域：\n",
      "\n",
      "- **自然语言处理（NLP）**：包括但不限于自动文摘、文本转语音、文本翻译、问答系统、文本生成。\n",
      "- **对话系统**：构建能够进行自然对话的聊天机器人。\n",
      "- **文本创作**：为小说、文章、剧本等创作提供灵感或全文生成。\n",
      "- **代码生成**：通过理解需求后自动生成部分或全部代码，减少人工编写工作。\n",
      "- **真实性和敏感性评估**：用于评估文本的真实性和潜在的偏见或敏感性。\n",
      "\n",
      "### 隐忧与挑战：\n",
      "\n",
      "尽管大型语言模型在许多应用上展现出惊人的能力，但它们也存在一些挑战和隐忧，包括但不限于：\n",
      "\n",
      "- **数据偏见**：模型可能会学习到训练数据中的偏见，从而产生不公平或有害的输出。\n",
      "- **隐私问题**：用于训练的大量数据可能包含个人隐私信息。\n",
      "- **泛化能力**：模型在处理未见数据或极端情况时的泛化能力有限，可能产生逻辑错误或产生难以预料的输出。\n",
      "\n",
      "### 总结：\n",
      "\n",
      "大型语言模型是现代人工智能领域中的一种强大工具，不仅丰富了我们与自然语言交互的方式，也在许多应用中展现出巨大的潜力。然而，它们的应用和发展需要持续关注其带来的社会和伦理问题，确保技术进步的同时，保障人性与福祉。\n",
      "--------------------------------------------------------------------------------\n",
      "{'type': 'openai', 'model': 'Qwen/Qwen2-7B-Instruct', 'base_url': 'http://localhost:8080/v1/'}\n",
      "stream=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 11-25 16:40:36 _client.py:1038 HTTP Request: POST http://localhost:8080/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO 11-25 16:40:36 _client.py:1038 HTTP Request: POST http://localhost:8080/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大型语言模型，又称为预训练语言模型，是一种基于深度学习的自然语言处理技术。这类模型通过大量文本数据进行预训练，学习到语言的普遍结构和规律，并在特定任务上进行微调，以解决特定的自然语言处理任务，如文本生成、问答、翻译、文本分类等。它们的规模通常非常大，包含数亿到数百亿的参数，这使得它们能够捕捉到非常复杂的语言模式。\n",
      "\n",
      "### 基本原理\n",
      "\n",
      "大型语言模型基于Transformer架构，这是一种能够高效处理序列数据的模型结构。Transformer模型通过自注意力机制来捕捉输入序列之间的依赖关系，而不是像传统的递归神经网络（RNN）那样顺序处理每个输入。这种机制使得模型能够并行处理大量数据，显著提高了训练和推理的速度。\n",
      "\n",
      "### 应用场景\n",
      "\n",
      "1. **文本生成**：根据给定的提示或输入，模型能够生成连续的文本，如文章、故事、代码、新闻等。\n",
      "2. **对话系统**：在聊天机器人、客服系统中，大型语言模型能够理解用户的输入并生成合适的响应。\n",
      "3. **机器翻译**：将一种语言的文本自动翻译成另一种语言。\n",
      "4. **文本摘要**：自动从长文本中提取关键信息并生成摘要。\n",
      "5. **问答系统**：回答基于文本的数据查询，如知识库检索、文档搜索等。\n",
      "\n",
      "### 代表性模型\n",
      "\n",
      "- **GPT**（Generative Pre-trained Transformer）系列：从GPT-1到GPT-3，每一版本参数量逐渐增加，性能显著提升。\n",
      "- **BERT**（Bidirectional Encoder Representations from Transformers）：通过双向上下文信息进行学习，提高了模型在多种NLP任务上的性能。\n",
      "- **T5**（Text to Text Transfer Transformer）：一个统一的模型，可以用于多种NLP任务，包括文本生成、问答、机器翻译等。\n",
      "\n",
      "### 面临的挑战与争议\n",
      "\n",
      "虽然大型语言模型在很多任务上取得了显著的进展，但也面临着一些挑战和争议，包括：\n",
      "\n",
      "- **数据偏见**：模型可能吸收训练数据中的偏见，影响其输出的公正性。\n",
      "- **安全与隐私**：模型可能被滥用，用于生成有害内容或泄露敏感信息。\n",
      "- **透明度与解释性**：大型模型的决策过程通常难以解释，这在某些关键应用（如医疗诊断）中是一个问题。\n",
      "\n",
      "随着技术的发展，研究者也在努力解决这些问题，使大型语言模型更加可靠、可控和安全。\n",
      "stream=True\n",
      "大型语言模型，通常被称为预训练语言模型（Pre-trained Language Models），是一种深度学习模型，主要用于理解、生成和生成人类自然语言。这些模型通过在大量文本数据上进行预训练，学习到语言的基本结构、语法和词汇的使用方式。它们被设计为能够处理多种任务，而无需针对特定任务进行额外的训练，这在机器学习领域被称为“多任务学习”。\n",
      "\n",
      "### 主要特点：\n",
      "\n",
      "1. **大规模训练数据**：大型语言模型通常在包含数十亿到数千亿个单词的大型语料库上进行训练，这使得它们能够学习到广泛的语言模式和表达方式。\n",
      "\n",
      "2. **自注意力机制**：这些模型广泛使用自注意力机制（self-attention mechanism），允许模型在处理文本时考虑不同单词之间的相互关系，从而提高了理解和生成文本的质量。\n",
      "\n",
      "3. **预训练+微调（fine-tuning）**：大型语言模型通常首先通过在大规模文本数据上进行预训练，然后在特定任务上进行微调，以适应不同的应用需求。\n",
      "\n",
      "4. **跨任务适应性**：预训练语言模型因其泛化的语言理解能力，可以应用于多种自然语言处理任务，包括但不限于文本分类、问答系统、文本生成、情感分析、机器翻译、代码生成等。\n",
      "\n",
      "### 应用实例：\n",
      "\n",
      "1. **文本生成**：可以用于创作故事、诗歌、对话等。\n",
      "2. **问答系统**：回答用户提出的自然语言问题。\n",
      "3. **代码生成**：根据需求自动生成代码片段。\n",
      "4. **文本翻译**：将文本从一种语言自动翻译成另一种语言。\n",
      "5. **文本理解和生成**：用于构建社交媒体分析、新闻摘要等。\n",
      "\n",
      "### 代表模型：\n",
      "\n",
      "- **BERT（Bidirectional Encoder Representations from Transformers）**\n",
      "- **GPT（Generative Pre-trained Transformer）系列**（包括GPT-1、GPT-2、GPT-3等）\n",
      "- **T5（Text-to-Text Transfer Transformer）**\n",
      "- **CodeBERT**\n",
      "- **MarianMT**（用于机器翻译）\n",
      "\n",
      "这些模型不仅在学术研究中被广泛探讨和应用，在商业领域也日益展现出其价值，例如在智能客服、内容生成、广告文案创作等领域。随着技术的持续发展，大型语言模型的应用前景将更加广阔。\n",
      "--------------------------------------------------------------------------------\n",
      "{'type': 'ollama', 'model': 'Qwen/Qwen2-7B-Instruct'}\n",
      "stream=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 11-25 16:40:52 _client.py:1038 HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO 11-25 16:40:52 _client.py:1038 HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大型语言模型，或称大模型，是深度学习领域发展的最新成果之一，主要指具有大量参数（通常数亿到数百亿或更多）的深度神经网络模型，专门用于处理语言任务，如文本生成、问答系统、语义理解、聊天机器人等等。这类模型通过在大量文本数据上学习分布式表示（通过自监督学习或预训练），能够生成流畅、合理甚至创造性的文本回复，并且具有在多种不同任务上进行微调以获得高效性能的能力，简化了专为特定任务训练模型的步骤。\n",
      "\n",
      "### 大型语言模型的关键特性与应用\n",
      "\n",
      "1. **参数量**：大型模型通常具有数亿到数百亿个参数，这使得它们能够捕捉到语言的复杂结构和细微差异。\n",
      "\n",
      "2. **自监督学习与大规模数据**：大模型通过在大量未标记文本数据上进行自我监督学习进行预训练，然后针对特定任务进行微调。这种方式允许模型学习到广泛的语言模式和语法结构。\n",
      "\n",
      "3. **多模态能力**：除了语言文本之外，一些大型语言模型如通义千问、LaMDA等还具有处理图形、图片、语音等多模态数据的能力，这是由其模块化或集成式结构实现的。\n",
      "\n",
      "4. **高效响应与生成质量**：大型模型能够快速生成高质量的文本回复，甚至具备创作故事、解释专业概念或回应复杂问题的能力。\n",
      "\n",
      "### 典型应用领域\n",
      "\n",
      "- **自然语言处理（NLP）**：实时对话系统、自动文本摘要、情感分析、机器翻译等。\n",
      "- **内容生成**：自动编写文章、创作诗歌、故事生成等。\n",
      "- **教育辅助**：个性化学习资源生成、自动出题等。\n",
      "- **个性化服务**：客服机器人、智能助理等提高客户体验。\n",
      "- **科学研究**：辅助生成假设、解释数据、执行文本总结等。\n",
      "\n",
      "大型语言模型正不断推动人工智能与人类交流方式的创新，它们的出现不仅在学术研究中引发了关注，在工业界也为众多产品和服务带来了革命性变化。随着技术的进一步发展，这些模型将来可能会在更多领域展现出强大的能力，改变人们工作和生活的方式。\n",
      "stream=True\n",
      "大型语言模型，也常被称为大语言模型、超大规模语言模型或超大规模AI模型，是一种基于深度学习技术的自然语言处理算法。这类模型从大量的文本数据中学习，包括但不限于书籍、网站内容、社交媒体文本、新闻文章等各类语言信息。由于其规模庞大，通常需要处理和存储数以百万计，甚至数十亿计的参数，故称为“大型”或“超大规模”的模型。\n",
      "\n",
      "在技术实现上，大型语言模型通常采用递归神经网络（RNN）、长短期记忆网络（LSTM）、门控循环单元（GRU）甚至Transformer架构等。这些模型利用大量文本数据训练而成，能够生成与训练数据集风格相似的文本，具备理解上下文、进行语法纠正、生成完整句子、回答问题、创作故事和诗篇以及构建对话等能力。\n",
      "\n",
      "大型语言模型的应用十分广泛，包括但不限于：\n",
      "\n",
      "1. **自动文本生成**：如自动生成新闻摘要、创作艺术作品、编写代码、诗歌等。\n",
      "2. **机器翻译**：将一种语言的文本翻译成另一种语言。\n",
      "3. **对话系统**：构建能够进行持续对话的虚拟助手或聊天机器人，提升客户体验或提供信息咨询。\n",
      "4. **文本理解和生成**：用于文本摘要、问答系统、聊天机器人等。\n",
      "5. **智能写作辅助**：如写作助手，能为用户提供大纲、提纲、文章段落等写作帮助。\n",
      "6. **语音识别和合成**：通过集成文本到语音技术，将生成的文本转化为语音。\n",
      "7. **个性化内容生成**：为用户提供定制化的内容，如新闻推荐、市场报告、用户手册等。\n",
      "\n",
      "大型语言模型的发展加速了人工智能与自然语言处理领域的进步，但同时也带来了一系列挑战，包括但不仅限于：\n",
      "\n",
      "- **数据隐私和安全**：处理大量的用户数据时涉及到隐私泄露的风险。\n",
      "- **伦理和责任**：模型可能会生成有害或不适当的内容，需要考虑到道德和责任问题。\n",
      "- **可解释性和可控性**：深度学习模型通常被认为是“黑盒”，缺乏足够的透明度和可解释性，用户难以理解模型如何做出决策。\n",
      "- **资源消耗**：训练和运行大型模型需要大量的计算资源和能源。\n",
      "\n",
      "尽管存在挑战，大型语言模型的潜力巨大，未来在提高效率、效率、性能以及提升模型的可控性、透明度和隐私保护等方面，研究人员正在持续探索创新解决方案。\n"
     ]
    }
   ],
   "source": [
    "for llm_config in [\n",
    "    {\"type\": \"zeroclient\", \"model\": model},\n",
    "    {\"type\": \"openai\", \"model\": model, \"base_url\": 'http://localhost:8080/v1/'},\n",
    "    {\"type\": \"ollama\", \"model\": model},\n",
    "]:\n",
    "    print(\"-\" * 80)\n",
    "    print(llm_config)\n",
    "    agent = LLMAgent(\n",
    "        name=\"chatbot\",\n",
    "        llm_config=llm_config,\n",
    "    )\n",
    "\n",
    "    print(\"stream=False\")\n",
    "    reply = agent.generate_reply(\n",
    "        messages=[{\"content\": prompt, \"role\": \"user\"}],\n",
    "        stream=False,\n",
    "        options={\"max_tokens\": 1000}\n",
    "    )\n",
    "\n",
    "    print(reply)\n",
    "\n",
    "    print(\"stream=True\")\n",
    "    for part in agent.generate_reply(\n",
    "        messages=[{\"content\": prompt, \"role\": \"user\"}],\n",
    "        stream=True,\n",
    "        options={\"max_tokens\": 1000}\n",
    "    ):\n",
    "        print(part, end=\"\", flush=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168d91f9",
   "metadata": {},
   "source": [
    "## 总结\n",
    "wde.agents 支持 ollama 和 openai客户端、支持 zeroclient 内部通讯协议。非常灵活。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78811193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
